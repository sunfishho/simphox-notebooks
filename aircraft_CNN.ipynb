{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9425075a-d65a-44a0-8daa-0a6d1cd730b0",
   "metadata": {},
   "source": [
    "# Scalability of *in situ* backpropagation\n",
    "\n",
    "In this notebook, we explore the scalability of *in situ* backpropagation as it pertains to the tradeoff between noise and energy efficiency and latency of photonic devices. \n",
    "- As far as scalability of the photonic advantage, we do our best to incorporate all of the different elements that contribute to the total energy consumption in the hybrid photonic neural network design, dominated by optoelectronic conversions and signal amplification, and any assumptions for this calculation are provided in the main text and/or Supplementary Material of the paper.\n",
    "- As far as noise error scaling, we explore the tradeoffs of various errors (e.g., systematic in the various photonic elements and random noise at the photodetector). We then perform large-scale simulations on MNIST data to show that realistic problems can be solved using our approach in the presence of error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69805b-3389-4631-a951-df5ebcec6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52cc7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e97baad-aa12-4e3a-a20a-aa1e4cd378bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_path = data_file_path + \"/images_manufacturer_train.txt\"\n",
    "y_test_path = data_file_path + \"/images_manufacturer_test.txt\"\n",
    "\n",
    "def populate_set(path):\n",
    "    manufacturer_dict = dict()\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip().split()\n",
    "            if len(line) == 2:\n",
    "                key = line[0]\n",
    "                value = line[1]\n",
    "                manufacturer_dict[key] = value\n",
    "    return manufacturer_dict\n",
    "\n",
    "y_train_dict = populate_set(y_train_path)\n",
    "y_test_dict = populate_set(y_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fa4078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ATR', 'Airbus', 'Antonov', 'Beechcraft', 'Boeing', 'Canadair', 'Cessna', 'Dornier', 'Embraer', 'Eurofighter', 'Fairchild', 'Fokker', 'Ilyushin', 'Panavia', 'Piper', 'Robin', 'Saab', 'Supermarine', 'Tupolev', 'Yakovlev']\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the manufacturers\n",
    "possible_labels = sorted(list(set(y_train_dict.values())))\n",
    "print(possible_labels)\n",
    "num_manufacturers = len(possible_labels)\n",
    "\n",
    "# one_hot_dict = {}\n",
    "# for manufacturer_idx in range(len(possible_labels)):\n",
    "#     one_hot_dict[possible_labels[manufacturer_idx]] = np.zeros(num_manufacturers)\n",
    "#     one_hot_dict[possible_labels[manufacturer_idx]][manufacturer_idx] = 1\n",
    "\n",
    "manufacturer_dict = {}\n",
    "\n",
    "for manufacturer_idx in range(len(possible_labels)):\n",
    "    manufacturer_dict[possible_labels[manufacturer_idx]] = manufacturer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7caec0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import norm_inputs\n",
    "\n",
    "WIDTH = 64\n",
    "\n",
    "x_train_raw = np.zeros((len(y_train_dict), WIDTH, WIDTH))\n",
    "x_test_raw = np.zeros((len(y_test_dict), WIDTH, WIDTH))\n",
    "# y_train = np.zeros((len(y_train_dict), num_manufacturers))\n",
    "y_train = np.zeros((len(y_train_dict),))\n",
    "# y_test = np.zeros((len(y_test_dict), num_manufacturers))\n",
    "y_test = np.zeros((len(y_test_dict),))\n",
    "\n",
    "\n",
    "def populate():\n",
    "    def populate_dataset(label_dict, data, labels):\n",
    "        counter = 0\n",
    "        for img_num in label_dict.keys():\n",
    "            path = f\"/Users/matthewho/Photonic_computing/simphox-notebooks/aircraft/fgvc-aircraft-2013b/data/images/{img_num}.jpg\"\n",
    "            img = Image.open(path)\n",
    "            img = img.convert('L')                                  # grayscale\n",
    "            width, height = img.size\n",
    "            cropped_img = img.crop((0, 0, width, height - 20))        # crop the copyright\n",
    "            filtered_img = cropped_img.filter(ImageFilter.GaussianBlur(radius = 5))    # not sure what to put as SD, putting 5 for now\n",
    "            downsampled_img = filtered_img.resize((WIDTH, WIDTH))         # downsample to 256 x 256\n",
    "            data[counter, :, :] = downsampled_img                     # add to x_train\n",
    "            # labels[counter,:] = one_hot_dict[label_dict[img_num]]     # add correct label\n",
    "            labels[counter] = manufacturer_dict[label_dict[img_num]]\n",
    "            counter += 1\n",
    "    populate_dataset(y_train_dict, x_train_raw, y_train)\n",
    "    populate_dataset(y_test_dict, x_test_raw, y_test)\n",
    "\n",
    "populate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3574e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perm = np.random.permutation(x_train_raw.shape[0])\n",
    "x_train_raw = x_train_raw[train_perm]\n",
    "y_train = y_train[train_perm]\n",
    "test_perm = np.random.permutation(x_test_raw.shape[0])\n",
    "x_test_raw = x_test_raw[test_perm]\n",
    "y_test = y_test[test_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de0018dc-66d4-4b99-90db-710811eb3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pixel = np.mean(np.vstack([x_train_raw, x_test_raw]))\n",
    "std_pixel = np.std(np.vstack([x_train_raw, x_test_raw]))\n",
    "\n",
    "x_train = (x_train_raw - mean_pixel)/std_pixel\n",
    "x_test = (x_test_raw - mean_pixel)/std_pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8266c2-959d-459b-8702-3003c3c6b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = np.shape(x_train)[0]\n",
    "NUM_TEST = np.shape(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2fe0557-8493-4bbe-b0e5-0eb87edbb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.expand_dims(x_train, axis = 1)), torch.from_numpy(y_train))\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(np.expand_dims(x_test, axis = 1)), torch.from_numpy(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec4721a-9456-459d-a654-6d3761a11657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f070d56-2134-474e-ab3b-c2ee908b90ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdbaeb2e-2ee0-4eb0-be7b-b53f04c4a53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# in theory they should be randomized already, but it doesn't hurt to randomly choose test data anyways\n",
    "aircraft_train = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                            sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "aircraft_test = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                           sampler=sampler.SubsetRandomSampler(range(NUM_TEST)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "932280f1-7ee7-41b1-8d1b-a080ec73c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0]\n",
    "    return x.view(N, -1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd4a455-7764-44c8-b696-e4c78295329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    # print('Checking accuracy on set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train(model, optimizer, epochs=50):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        print(f\"Epoch number: {e}\")\n",
    "        for t, (x, y) in enumerate(aircraft_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Loss = %.4f' % (loss.item()))\n",
    "                print(\"Train accuracy:\")\n",
    "                check_accuracy(aircraft_train, model)\n",
    "                print(\"Test accuracy:\")\n",
    "                check_accuracy(aircraft_test, model)\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5248c210-01f8-4a05-9b1c-78aff127f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0\n",
      "Loss = 2.9950\n",
      "Train accuracy:\n",
      "Got 373 / 2367 correct (15.76)\n",
      "Test accuracy:\n",
      "Got 375 / 2368 correct (15.84)\n",
      "\n",
      "Epoch number: 1\n",
      "Loss = 2.3649\n",
      "Train accuracy:\n",
      "Got 733 / 2367 correct (30.97)\n",
      "Test accuracy:\n",
      "Got 734 / 2368 correct (31.00)\n",
      "\n",
      "Epoch number: 2\n",
      "Loss = 2.1492\n",
      "Train accuracy:\n",
      "Got 753 / 2367 correct (31.81)\n",
      "Test accuracy:\n",
      "Got 730 / 2368 correct (30.83)\n",
      "\n",
      "Epoch number: 3\n",
      "Loss = 1.9978\n",
      "Train accuracy:\n",
      "Got 787 / 2367 correct (33.25)\n",
      "Test accuracy:\n",
      "Got 684 / 2368 correct (28.89)\n",
      "\n",
      "Epoch number: 4\n",
      "Loss = 2.0483\n",
      "Train accuracy:\n",
      "Got 839 / 2367 correct (35.45)\n",
      "Test accuracy:\n",
      "Got 716 / 2368 correct (30.24)\n",
      "\n",
      "Epoch number: 5\n",
      "Loss = 1.8814\n",
      "Train accuracy:\n",
      "Got 920 / 2367 correct (38.87)\n",
      "Test accuracy:\n",
      "Got 728 / 2368 correct (30.74)\n",
      "\n",
      "Epoch number: 6\n",
      "Loss = 1.9257\n",
      "Train accuracy:\n",
      "Got 960 / 2367 correct (40.56)\n",
      "Test accuracy:\n",
      "Got 749 / 2368 correct (31.63)\n",
      "\n",
      "Epoch number: 7\n",
      "Loss = 1.6156\n",
      "Train accuracy:\n",
      "Got 1027 / 2367 correct (43.39)\n",
      "Test accuracy:\n",
      "Got 765 / 2368 correct (32.31)\n",
      "\n",
      "Epoch number: 8\n",
      "Loss = 1.9911\n",
      "Train accuracy:\n",
      "Got 1094 / 2367 correct (46.22)\n",
      "Test accuracy:\n",
      "Got 788 / 2368 correct (33.28)\n",
      "\n",
      "Epoch number: 9\n",
      "Loss = 1.6675\n",
      "Train accuracy:\n",
      "Got 1050 / 2367 correct (44.36)\n",
      "Test accuracy:\n",
      "Got 793 / 2368 correct (33.49)\n",
      "\n",
      "Epoch number: 10\n",
      "Loss = 1.9929\n",
      "Train accuracy:\n",
      "Got 1184 / 2367 correct (50.02)\n",
      "Test accuracy:\n",
      "Got 804 / 2368 correct (33.95)\n",
      "\n",
      "Epoch number: 11\n",
      "Loss = 1.6937\n",
      "Train accuracy:\n",
      "Got 1272 / 2367 correct (53.74)\n",
      "Test accuracy:\n",
      "Got 808 / 2368 correct (34.12)\n",
      "\n",
      "Epoch number: 12\n",
      "Loss = 1.5123\n",
      "Train accuracy:\n",
      "Got 1337 / 2367 correct (56.49)\n",
      "Test accuracy:\n",
      "Got 833 / 2368 correct (35.18)\n",
      "\n",
      "Epoch number: 13\n",
      "Loss = 1.6866\n",
      "Train accuracy:\n",
      "Got 1405 / 2367 correct (59.36)\n",
      "Test accuracy:\n",
      "Got 852 / 2368 correct (35.98)\n",
      "\n",
      "Epoch number: 14\n",
      "Loss = 1.3621\n",
      "Train accuracy:\n",
      "Got 1407 / 2367 correct (59.44)\n",
      "Test accuracy:\n",
      "Got 860 / 2368 correct (36.32)\n",
      "\n",
      "Epoch number: 15\n",
      "Loss = 1.5543\n",
      "Train accuracy:\n",
      "Got 1470 / 2367 correct (62.10)\n",
      "Test accuracy:\n",
      "Got 856 / 2368 correct (36.15)\n",
      "\n",
      "Epoch number: 16\n",
      "Loss = 1.3091\n",
      "Train accuracy:\n",
      "Got 1514 / 2367 correct (63.96)\n",
      "Test accuracy:\n",
      "Got 865 / 2368 correct (36.53)\n",
      "\n",
      "Epoch number: 17\n",
      "Loss = 1.4498\n",
      "Train accuracy:\n",
      "Got 1560 / 2367 correct (65.91)\n",
      "Test accuracy:\n",
      "Got 886 / 2368 correct (37.42)\n",
      "\n",
      "Epoch number: 18\n",
      "Loss = 1.2233\n",
      "Train accuracy:\n",
      "Got 1633 / 2367 correct (68.99)\n",
      "Test accuracy:\n",
      "Got 908 / 2368 correct (38.34)\n",
      "\n",
      "Epoch number: 19\n",
      "Loss = 1.3214\n",
      "Train accuracy:\n",
      "Got 1691 / 2367 correct (71.44)\n",
      "Test accuracy:\n",
      "Got 926 / 2368 correct (39.10)\n",
      "\n",
      "Epoch number: 20\n",
      "Loss = 1.2418\n",
      "Train accuracy:\n",
      "Got 1735 / 2367 correct (73.30)\n",
      "Test accuracy:\n",
      "Got 913 / 2368 correct (38.56)\n",
      "\n",
      "Epoch number: 21\n",
      "Loss = 1.3112\n",
      "Train accuracy:\n",
      "Got 1791 / 2367 correct (75.67)\n",
      "Test accuracy:\n",
      "Got 924 / 2368 correct (39.02)\n",
      "\n",
      "Epoch number: 22\n",
      "Loss = 1.4201\n",
      "Train accuracy:\n",
      "Got 1818 / 2367 correct (76.81)\n",
      "Test accuracy:\n",
      "Got 934 / 2368 correct (39.44)\n",
      "\n",
      "Epoch number: 23\n",
      "Loss = 1.2238\n",
      "Train accuracy:\n",
      "Got 1792 / 2367 correct (75.71)\n",
      "Test accuracy:\n",
      "Got 953 / 2368 correct (40.24)\n",
      "\n",
      "Epoch number: 24\n",
      "Loss = 1.3742\n",
      "Train accuracy:\n",
      "Got 1899 / 2367 correct (80.23)\n",
      "Test accuracy:\n",
      "Got 952 / 2368 correct (40.20)\n",
      "\n",
      "Epoch number: 25\n",
      "Loss = 1.0003\n",
      "Train accuracy:\n",
      "Got 1932 / 2367 correct (81.62)\n",
      "Test accuracy:\n",
      "Got 950 / 2368 correct (40.12)\n",
      "\n",
      "Epoch number: 26\n",
      "Loss = 1.0997\n",
      "Train accuracy:\n",
      "Got 1978 / 2367 correct (83.57)\n",
      "Test accuracy:\n",
      "Got 933 / 2368 correct (39.40)\n",
      "\n",
      "Epoch number: 27\n",
      "Loss = 1.2080\n",
      "Train accuracy:\n",
      "Got 2011 / 2367 correct (84.96)\n",
      "Test accuracy:\n",
      "Got 924 / 2368 correct (39.02)\n",
      "\n",
      "Epoch number: 28\n",
      "Loss = 1.1313\n",
      "Train accuracy:\n",
      "Got 1981 / 2367 correct (83.69)\n",
      "Test accuracy:\n",
      "Got 976 / 2368 correct (41.22)\n",
      "\n",
      "Epoch number: 29\n",
      "Loss = 0.9006\n",
      "Train accuracy:\n",
      "Got 2000 / 2367 correct (84.50)\n",
      "Test accuracy:\n",
      "Got 972 / 2368 correct (41.05)\n",
      "\n",
      "Epoch number: 30\n",
      "Loss = 0.9927\n",
      "Train accuracy:\n",
      "Got 2089 / 2367 correct (88.26)\n",
      "Test accuracy:\n",
      "Got 971 / 2368 correct (41.01)\n",
      "\n",
      "Epoch number: 31\n",
      "Loss = 0.9856\n",
      "Train accuracy:\n",
      "Got 2101 / 2367 correct (88.76)\n",
      "Test accuracy:\n",
      "Got 955 / 2368 correct (40.33)\n",
      "\n",
      "Epoch number: 32\n",
      "Loss = 0.8660\n",
      "Train accuracy:\n",
      "Got 2121 / 2367 correct (89.61)\n",
      "Test accuracy:\n",
      "Got 979 / 2368 correct (41.34)\n",
      "\n",
      "Epoch number: 33\n",
      "Loss = 0.8745\n",
      "Train accuracy:\n",
      "Got 2140 / 2367 correct (90.41)\n",
      "Test accuracy:\n",
      "Got 981 / 2368 correct (41.43)\n",
      "\n",
      "Epoch number: 34\n",
      "Loss = 0.8298\n",
      "Train accuracy:\n",
      "Got 2137 / 2367 correct (90.28)\n",
      "Test accuracy:\n",
      "Got 979 / 2368 correct (41.34)\n",
      "\n",
      "Epoch number: 35\n",
      "Loss = 0.9708\n",
      "Train accuracy:\n",
      "Got 2122 / 2367 correct (89.65)\n",
      "Test accuracy:\n",
      "Got 1007 / 2368 correct (42.53)\n",
      "\n",
      "Epoch number: 36\n",
      "Loss = 0.7208\n",
      "Train accuracy:\n",
      "Got 2155 / 2367 correct (91.04)\n",
      "Test accuracy:\n",
      "Got 997 / 2368 correct (42.10)\n",
      "\n",
      "Epoch number: 37\n",
      "Loss = 0.7823\n",
      "Train accuracy:\n",
      "Got 2160 / 2367 correct (91.25)\n",
      "Test accuracy:\n",
      "Got 1001 / 2368 correct (42.27)\n",
      "\n",
      "Epoch number: 38\n",
      "Loss = 0.9022\n",
      "Train accuracy:\n",
      "Got 2181 / 2367 correct (92.14)\n",
      "Test accuracy:\n",
      "Got 984 / 2368 correct (41.55)\n",
      "\n",
      "Epoch number: 39\n",
      "Loss = 1.1860\n",
      "Train accuracy:\n",
      "Got 2172 / 2367 correct (91.76)\n",
      "Test accuracy:\n",
      "Got 1007 / 2368 correct (42.53)\n",
      "\n",
      "Epoch number: 40\n",
      "Loss = 0.7051\n",
      "Train accuracy:\n",
      "Got 2146 / 2367 correct (90.66)\n",
      "Test accuracy:\n",
      "Got 1033 / 2368 correct (43.62)\n",
      "\n",
      "Epoch number: 41\n",
      "Loss = 0.8710\n",
      "Train accuracy:\n",
      "Got 2200 / 2367 correct (92.94)\n",
      "Test accuracy:\n",
      "Got 1017 / 2368 correct (42.95)\n",
      "\n",
      "Epoch number: 42\n",
      "Loss = 0.8522\n",
      "Train accuracy:\n",
      "Got 2222 / 2367 correct (93.87)\n",
      "Test accuracy:\n",
      "Got 1014 / 2368 correct (42.82)\n",
      "\n",
      "Epoch number: 43\n",
      "Loss = 0.8089\n",
      "Train accuracy:\n",
      "Got 2234 / 2367 correct (94.38)\n",
      "Test accuracy:\n",
      "Got 1002 / 2368 correct (42.31)\n",
      "\n",
      "Epoch number: 44\n",
      "Loss = 0.8387\n",
      "Train accuracy:\n",
      "Got 2185 / 2367 correct (92.31)\n",
      "Test accuracy:\n",
      "Got 1024 / 2368 correct (43.24)\n",
      "\n",
      "Epoch number: 45\n",
      "Loss = 0.5719\n",
      "Train accuracy:\n",
      "Got 2244 / 2367 correct (94.80)\n",
      "Test accuracy:\n",
      "Got 1014 / 2368 correct (42.82)\n",
      "\n",
      "Epoch number: 46\n",
      "Loss = 0.8019\n",
      "Train accuracy:\n",
      "Got 2257 / 2367 correct (95.35)\n",
      "Test accuracy:\n",
      "Got 1005 / 2368 correct (42.44)\n",
      "\n",
      "Epoch number: 47\n",
      "Loss = 0.4832\n",
      "Train accuracy:\n",
      "Got 2238 / 2367 correct (94.55)\n",
      "Test accuracy:\n",
      "Got 1025 / 2368 correct (43.29)\n",
      "\n",
      "Epoch number: 48\n",
      "Loss = 0.4402\n",
      "Train accuracy:\n",
      "Got 2228 / 2367 correct (94.13)\n",
      "Test accuracy:\n",
      "Got 1007 / 2368 correct (42.53)\n",
      "\n",
      "Epoch number: 49\n",
      "Loss = 0.4887\n",
      "Train accuracy:\n",
      "Got 2259 / 2367 correct (95.44)\n",
      "Test accuracy:\n",
      "Got 1003 / 2368 correct (42.36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "channel_1 = 16\n",
    "channel_2 = 8\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, channel_1, 5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    Flatten(),\n",
    "    nn.Dropout(p=0.8),\n",
    "    nn.Linear(channel_2 * WIDTH * WIDTH, num_manufacturers)\n",
    ")\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef33ee-3536-4b00-86e4-acb3fcfc403f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
