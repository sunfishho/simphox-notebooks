{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b2db4e83-456f-407f-ac64-157edc026caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchonn as onn\n",
    "from torchonn.models import ONNBaseModel\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchonn.op.mzi_op import project_matrix_to_unitary\n",
    "import scipy.stats as stats\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "38632d87-2e90-4e52-8856-be7ab5a76b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3407)\n",
    "\n",
    "class ONNModel(ONNBaseModel):\n",
    "    def __init__(self, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.counter = 0\n",
    "        self.linear0 = onn.layers.MZIBlockLinear(\n",
    "            in_features=28*28,\n",
    "            out_features=100, # because we're doing 5-way\n",
    "            bias=False,\n",
    "            miniblock=4,\n",
    "            mode=\"usv\",\n",
    "            decompose_alg=\"clements\",\n",
    "            photodetect=True,\n",
    "            device=device,\n",
    "        )\n",
    "        # self.linear1 = onn.layers.MZIBlockLinear(\n",
    "        #     in_features=100,\n",
    "        #     out_features=5, # because we're doing 5-way\n",
    "        #     bias=False,\n",
    "        #     miniblock=4,\n",
    "        #     mode=\"usv\",\n",
    "        #     decompose_alg=\"clements\",\n",
    "        #     photodetect=True,\n",
    "        #     device=device,\n",
    "        # )\n",
    "        self.linear0.reset_parameters()\n",
    "        # self.linear1.reset_parameters()\n",
    "\n",
    "    def unitary_projection(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, onn.layers.MZIBlockLinear):\n",
    "                # print(f\"U is: {m.U.data}\")\n",
    "                m.U.data.copy_(project_matrix_to_unitary(m.U.data))\n",
    "                m.V.data.copy_(project_matrix_to_unitary(m.V.data))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # if self.counter < 7:\n",
    "        #     print(self.linear0.U)\n",
    "        #     self.counter += 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.linear0(x))\n",
    "        # x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a325967d-916d-4349-9c53-b519936950c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 5\n",
    "\n",
    "def normalize_grads(grad):\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(g.detach()).to(device) for g in grad]))\n",
    "    clip_coef_clamped = torch.clamp(max_norm/(total_norm + 1e-6), max = 1.0)\n",
    "    for g in grad:\n",
    "        g.detach().mul_(clip_coef_clamped.to(g.device))\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    # note that the maml-pytorch library uses an argparser to handle most of this instead of passing in individual parameters\n",
    "    def __init__(self, update_lr, meta_lr, n_way, k_spt, k_qry, task_num, update_step, update_step_test):\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        \n",
    "        super(Meta, self).__init__()\n",
    "        self.net = ONNModel()\n",
    "        self.net.train()\n",
    "        self.meta_optim = optim.Adam(list(self.net.parameters()), lr=self.meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        y_spt = y_spt.to(torch.int64)\n",
    "        y_qry = y_qry.to(torch.int64)\n",
    "        task_num, setsz, c_, h, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "        for i in range(task_num):\n",
    "            # might need to clip grad norms here later\n",
    "\n",
    "            # calculate loss before any update\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i])\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] += correct\n",
    "                \n",
    "            for k in range(self.update_step):\n",
    "                logits = self.net(x_spt[i])\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, list(self.net.parameters()), create_graph=True)\n",
    "                normalize_grads(grad)\n",
    "                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, list(self.net.parameters()))))\n",
    "                # set new net values\n",
    "                for l, param in enumerate(self.net.parameters()):\n",
    "                    param.data = nn.parameter.Parameter(torch.clone(fast_weights[l]))\n",
    "                # PROJECT TO UNITARY\n",
    "                # print(self.net.linear0.U)\n",
    "                self.net.unitary_projection()\n",
    "                # apply to query\n",
    "                logits_q = self.net(x_qry[i])\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] += correct\n",
    "                    \n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.retain_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "        # is this needed?\n",
    "        self.net.unitary_projection()\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetuning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        y_spt = y_spt.to(torch.int64)\n",
    "        y_qry = y_qry.to(torch.int64)\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        normalize_grads(grad)\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry)\n",
    "            pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] += correct\n",
    "        for k in range(self.update_step_test):\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, list(net.parameters()))))\n",
    "            for l, param in enumerate(net.parameters()):\n",
    "                param.data = nn.parameter.Parameter(torch.clone(fast_weights[l]))\n",
    "            net.unitary_projection()\n",
    "            logits = net(x_spt)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, net.parameters())\n",
    "            normalize_grads(grad)\n",
    "            logits_q = net(x_qry)\n",
    "            loss_q = F.cross_entropy(logits_q, y_qry)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] += correct\n",
    "        del net\n",
    "        return np.array(corrects)/querysz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0d134778-a40f-493a-a23d-c466a2eae973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "db_train = OmniglotLoader(batch_size = 32, n_way = 5, k_spt = 1, k_qry = 15, downsampled_size = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b935d6c9-0705-4660-91d4-5ec402c252d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "maml = Meta(update_lr = 0.01, meta_lr = 0.001, n_way = 5, k_spt = 1, k_qry = 15, task_num = 32, update_step = 5, update_step_test = 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "64c1f4f4-e3b8-4a72-9b0d-e0c328a1732c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.1925     0.1875     0.20458333 0.19375    0.20541667 0.19875   ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[345], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m x_spt, y_spt, x_qry, y_qry \u001b[38;5;241m=\u001b[39m db_train\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m      5\u001b[0m x_spt, y_spt, x_qry, y_qry \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_spt)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_spt)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x_qry)\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_qry)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m accs \u001b[38;5;241m=\u001b[39m \u001b[43mmaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_spt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_qry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_qry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep:\u001b[39m\u001b[38;5;124m'\u001b[39m, step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mtraining acc:\u001b[39m\u001b[38;5;124m'\u001b[39m, accs)\n",
      "File \u001b[0;32m~/Photonic_computing/photonics_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[343], line 57\u001b[0m, in \u001b[0;36mMeta.forward\u001b[0;34m(self, x_spt, y_spt, x_qry, y_qry)\u001b[0m\n\u001b[1;32m     54\u001b[0m     param\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mclone(fast_weights[l]))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# PROJECT TO UNITARY\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# print(self.net.linear0.U)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munitary_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# apply to query\u001b[39;00m\n\u001b[1;32m     59\u001b[0m logits_q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(x_qry[i])\n",
      "Cell \u001b[0;32mIn[315], line 35\u001b[0m, in \u001b[0;36mONNModel.unitary_projection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, onn\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMZIBlockLinear):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# print(f\"U is: {m.U.data}\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     m\u001b[38;5;241m.\u001b[39mU\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(project_matrix_to_unitary(m\u001b[38;5;241m.\u001b[39mU\u001b[38;5;241m.\u001b[39mdata))\n\u001b[0;32m---> 35\u001b[0m     m\u001b[38;5;241m.\u001b[39mV\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcopy_(\u001b[43mproject_matrix_to_unitary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Photonic_computing/pytorch-onn/torchonn/op/mzi_op.py:531\u001b[0m, in \u001b[0;36mproject_matrix_to_unitary\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m    529\u001b[0m     U_refine \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(U, V)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(W, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 531\u001b[0m     U, _, V \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m     U_refine \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(U, V\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for step in range(num_epochs):\n",
    "    x_spt, y_spt, x_qry, y_qry = db_train.next()\n",
    "    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).to(device), torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).to(device)\n",
    "\n",
    "    accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        print('step:', step, '\\ttraining acc:', accs)\n",
    "\n",
    "    if step % 500 == 0 and step > 0:\n",
    "        accs = []\n",
    "        for _ in range(1000//32):\n",
    "            # test\n",
    "            x_spt, y_spt, x_qry, y_qry = db_train.next('test')\n",
    "            x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).to(device), \\\n",
    "                                        torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).to(device)\n",
    "            # split to single task each time\n",
    "            for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, y_spt, x_qry, y_qry):\n",
    "                test_acc = maml.finetuning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n",
    "                accs.append(test_acc)\n",
    "        accs = np.array(accs).mean(axis = 0).astype(np.float16)\n",
    "        print('Test acc:', accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c27f1-7a05-4c11-9d09-f64a0c714dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
