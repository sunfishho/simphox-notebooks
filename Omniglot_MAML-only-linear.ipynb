{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b2db4e83-456f-407f-ac64-157edc026caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchonn as onn\n",
    "from torchonn.models import ONNBaseModel\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchonn.op.mzi_op import project_matrix_to_unitary\n",
    "import scipy.stats as stats\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "38632d87-2e90-4e52-8856-be7ab5a76b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3407)\n",
    "\n",
    "class ONNModel(ONNBaseModel):\n",
    "    def __init__(self, device=torch.device(\"cpu\")):\n",
    "        super().__init__()\n",
    "        self.linear0 = onn.layers.MZIBlockLinear(\n",
    "            in_features=28,\n",
    "            out_features=100,\n",
    "            bias=False,\n",
    "            miniblock=1,\n",
    "            mode=\"usv\",\n",
    "            decompose_alg=\"clements\",\n",
    "            photodetect=True,\n",
    "            device=device,\n",
    "        )\n",
    "        self.linear1 = onn.layers.MZIBlockLinear(\n",
    "            in_features=100,\n",
    "            out_features=5, # because we're doing 5-way\n",
    "            bias=False,\n",
    "            miniblock=1,\n",
    "            mode=\"usv\",\n",
    "            decompose_alg=\"clements\",\n",
    "            photodetect=True,\n",
    "            device=device,\n",
    "        )\n",
    "        self.linear0.reset_parameters()\n",
    "        self.linear1.reset_parameters()\n",
    "\n",
    "    def unitary_projection(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, onn.layers.MZIBlockLinear):\n",
    "                # print(f\"U is: {m.U.data}\")\n",
    "                m.U.data.copy_(project_matrix_to_unitary(m.U.data))\n",
    "                m.V.data.copy_(project_matrix_to_unitary(m.V.data))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear0(x))\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a325967d-916d-4349-9c53-b519936950c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 5\n",
    "\n",
    "def normalize_grads(grad):\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(g.detach()).to(device) for g in grad]))\n",
    "    clip_coef_clamped = torch.clamp(max_norm/(total_norm + 1e-6), max = 1.0)\n",
    "    for g in grad:\n",
    "        g.detach().mul_(clip_coef_clamped.to(g.device))\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    # note that the maml-pytorch library uses an argparser to handle most of this instead of passing in individual parameters\n",
    "    def __init__(self, update_lr, meta_lr, n_way, k_spt, k_qry, task_num, update_step, update_step_test):\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        \n",
    "        super(Meta, self).__init__()\n",
    "        self.net = ONNModel()\n",
    "        self.net.train()\n",
    "        self.meta_optim = optim.Adam(list(self.net.parameters()), lr=self.meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        y_spt = y_spt.to(torch.int64)\n",
    "        y_qry = y_qry.to(torch.int64)\n",
    "        task_num, setsz, c_, h, w = x_spt.size()\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]  # losses_q[i] is the loss on step i\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "        for i in range(task_num):\n",
    "            # might need to clip grad norms here later\n",
    "\n",
    "            # calculate loss before any update\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i])\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] += correct\n",
    "                \n",
    "            for k in range(self.update_step):\n",
    "                logits = self.net(x_spt[i])\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, list(self.net.parameters()), create_graph=True)\n",
    "                normalize_grads(grad)\n",
    "                fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, list(self.net.parameters()))))\n",
    "                # set new net values\n",
    "                for l, param in enumerate(self.net.parameters()):\n",
    "                    param.data = nn.parameter.Parameter(torch.clone(fast_weights[l]))\n",
    "                # PROJECT TO UNITARY\n",
    "                # print(self.net.linear0.U)\n",
    "                self.net.unitary_projection()\n",
    "                # apply to query\n",
    "                logits_q = self.net(x_qry[i])\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] += correct\n",
    "                    \n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.retain_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "        # is this needed?\n",
    "        self.net.unitary_projection()\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetuning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        y_spt = y_spt.to(torch.int64)\n",
    "        y_qry = y_qry.to(torch.int64)\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        normalize_grads(grad)\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry)\n",
    "            pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] += correct\n",
    "        for k in range(self.update_step_test):\n",
    "            fast_weights = list(map(lambda p: p[1] - self.update_lr * p[0], zip(grad, list(net.parameters()))))\n",
    "            for l, param in enumerate(net.parameters()):\n",
    "                param.data = nn.parameter.Parameter(torch.clone(fast_weights[l]))\n",
    "            net.unitary_projection()\n",
    "            logits = net(x_spt)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, net.parameters())\n",
    "            normalize_grads(grad)\n",
    "            logits_q = net(x_qry)\n",
    "            loss_q = F.cross_entropy(logits_q, y_qry)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim = 1).argmax(dim = 1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] += correct\n",
    "        del net\n",
    "        return np.array(corrects)/querysz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0d134778-a40f-493a-a23d-c466a2eae973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "db_train = OmniglotLoader(batch_size = 32, n_way = 5, k_spt = 1, k_qry = 15, downsampled_size = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b935d6c9-0705-4660-91d4-5ec402c252d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "maml = Meta(update_lr = 0.01, meta_lr = 0.001, n_way = 5, k_spt = 1, k_qry = 15, task_num = 32, update_step = 5, update_step_test = 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c1f4f4-e3b8-4a72-9b0d-e0c328a1732c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.         0.00041667 0.00083333 0.00083333 0.00041667 0.00041667]\n",
      "step: 5 \ttraining acc: [0.13       0.13458333 0.13958333 0.13625    0.13       0.13375   ]\n",
      "step: 10 \ttraining acc: [0.1575     0.17       0.16375    0.1725     0.16458333 0.17083333]\n",
      "step: 15 \ttraining acc: [0.16833333 0.16916667 0.16958333 0.16875    0.17166667 0.16958333]\n",
      "step: 20 \ttraining acc: [0.17166667 0.17625    0.17166667 0.17458333 0.17125    0.17458333]\n",
      "step: 25 \ttraining acc: [0.155      0.16208333 0.16041667 0.16375    0.1675     0.16083333]\n",
      "step: 30 \ttraining acc: [0.1775     0.175      0.18291667 0.17375    0.18416667 0.17375   ]\n",
      "step: 35 \ttraining acc: [0.18041667 0.17958333 0.18083333 0.17666667 0.17833333 0.175     ]\n",
      "step: 40 \ttraining acc: [0.18125    0.17958333 0.18458333 0.17958333 0.18208333 0.18166667]\n",
      "step: 45 \ttraining acc: [0.18375    0.1825     0.18333333 0.18416667 0.18541667 0.18541667]\n",
      "step: 50 \ttraining acc: [0.17       0.16833333 0.17083333 0.16583333 0.17083333 0.16416667]\n",
      "step: 55 \ttraining acc: [0.16833333 0.17375    0.16875    0.17291667 0.17541667 0.175     ]\n",
      "step: 60 \ttraining acc: [0.17666667 0.18583333 0.17958333 0.18625    0.17958333 0.18666667]\n",
      "step: 65 \ttraining acc: [0.1775     0.17458333 0.18083333 0.17625    0.17958333 0.17541667]\n",
      "step: 70 \ttraining acc: [0.18458333 0.18166667 0.18625    0.17708333 0.18625    0.175     ]\n",
      "step: 75 \ttraining acc: [0.17083333 0.17       0.17291667 0.17041667 0.17416667 0.17083333]\n",
      "step: 80 \ttraining acc: [0.18125    0.18208333 0.18375    0.18       0.18166667 0.17958333]\n",
      "step: 85 \ttraining acc: [0.1825     0.18541667 0.18416667 0.18625    0.18333333 0.18625   ]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "\n",
    "for step in range(num_epochs):\n",
    "    x_spt, y_spt, x_qry, y_qry = db_train.next()\n",
    "    x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).to(device), torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).to(device)\n",
    "\n",
    "    accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "    if step % 5 == 0:\n",
    "        print('step:', step, '\\ttraining acc:', accs)\n",
    "\n",
    "    if step % 500 == 0 and step > 0:\n",
    "        accs = []\n",
    "        for _ in range(1000//32):\n",
    "            # test\n",
    "            x_spt, y_spt, x_qry, y_qry = db_train.next('test')\n",
    "            x_spt, y_spt, x_qry, y_qry = torch.from_numpy(x_spt).to(device), torch.from_numpy(y_spt).to(device), \\\n",
    "                                        torch.from_numpy(x_qry).to(device), torch.from_numpy(y_qry).to(device)\n",
    "            # split to single task each time\n",
    "            for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, y_spt, x_qry, y_qry):\n",
    "                test_acc = maml.finetuning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n",
    "                accs.append(test_acc)\n",
    "        accs = np.array(accs).mean(axis = 0).astype(np.float16)\n",
    "        print('Test acc:', accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c27f1-7a05-4c11-9d09-f64a0c714dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
